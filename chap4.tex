\chapter{实验与分析}
在上两章的理论中，我们提出了基于决断集模板进行溯因诊断的方法，因此在本章中我们进行了两组实验来对上述理论进行验证。在第一组实验中，我们主要观察基于决断集模板的解释的基数生成解释的数量的影响以及对系统运算时间的影响。在第二组实验中我们重点验证生成的解释对知识库模型的诊断修复效果。

\section{实验工具与环境}
在本文中，我们实现了算法1中的算法逻辑，并把程序命名成Pattern Based Abduction(PBA)。PBA是一个用Java写成的程序，其中我们使用了本体语言编辑库OWL API来进行本体的生成、编辑与持久化存储，本体语言的推理机我们使用的是 Pellet API\cite{SPGKK07}，我们利用Pellet API完成的主要任务包括蕴含检测，蕴含寻找以及一致性检测。我们使用的数据库系统是Mysql，利用Mysql我们主要完成以下几个任务：第一是完成数据的存储。这里的数据主要包括本体中的ABox，训练集的数据和测试数据，实验完成后生成的解释集合也会存储在相同数据库的不同表中。使用Mysql完成的第二个主要任务是寻找差异化实例替换$\theta$。通过把决断集模板编译成sql语句后，我们可以根据数据库中的ABox计算出相对应的差异化实例替换$\theta$。本文实验中用到的实验数据如下表：

\begin{table}[!h]
	\caption{实验工具}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
{\rule{\temptablewidth}{1pt}}\\
\begin{tabular}{c|c}
    工具 & 描述  \\
    \hline
    开发语言 & Java \\
    \hline
    JDK & 7u121-2.6.8-1ubuntu0.14.04.3  \\
    \hline
    数据库 & Mysql(vesion 5.7)\\
    \hline
    本体编辑库 & OWL API(vesion 3.5.1)\\
	\hline
    本体推理机 & Pellet API(version 2.3.1)\\
	\hline
\end{tabular}\\
{\rule{\temptablewidth}{1pt}}
\end{center}
\vspace*{-5mm}
\end{table}



本次实验的数据，我们使用了两组数据，它们都来自FreeBase，分别是FB15K和FB40K。因为我们的问题输入还有一项是观察值，因此这些数据我们没有直接使用。我们从FB15K的有效三元组中抽取了1295组作为我们求问题的输入，也就是观察值，同时也会从训练集中把这1295组三元组移除，以避免影响实验结果。 它们的具体数据如下表[ptranse]：
\begin{table}[!h]
\caption{FreeBase数据集相关数据}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
\begin{tabular}{c|ccccc}
	\hline
    Dataset & \#Rel & \#Ent & \#Train & \#Valid & \#Observation  \\
    \hline
    FB15K & 1,345 & 14,951 & 483,142 & 50,000 & 59,071 \\
    \hline
    FB40K & 1,336 & 39,528 & 370,648 & 67,946 & 96,678 \\
	\hline
\end{tabular}\\
\end{center}
\vspace*{-5mm}
\end{table}

我们所有的实验运行在同一台机器上，机器的配置如下：
	\begin{table}[!h]
	\caption{实验环境}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
{\rule{\temptablewidth}{1pt}}\\
\begin{tabular}{c|c}
    环境 & 描述  \\
    \hline
    CPU & 1.4 GHz Intel Core i5 \\
    \hline
    RAM & 4GB  \\
    \hline
    OS & OS X Yosemite 10.10.3\\
    \hline
    Java Heap Space & 4GB
\end{tabular}\\
{\rule{\temptablewidth}{1pt}}
\end{center}
\vspace*{-5mm}
\end{table}

\section{程序框架}
系统PBA采取了分模块设计，所有的模块如图4.1所示，其中数据解析模块负责对输入的数据集进行解析，并结合本体编辑推理模块完成对数据集的语义表达。本体编辑推理模块除了完成对数据集语义表达的任务以外，还需要完成本体编辑存储以及推理任务，其中推理模块需要在解释生成的过程中对生成的本体和解释进行一致性检测，并验证临时本体是否能够蕴含蕴含值(或观察值)。决断集模板编译模块主要完成寻找差异化实例替换$\theta$的任务。寻找
差异化实例替换$\theta$的任务可以在内存中通过搜索的方式找到，并且计算速度较快，但是因为计算机资源有限，而数据的增大有可能导致计算任务的无法完成，所以我们会把在内存中完成差异化实例替换$\theta$的这种方式称为不可扩展的。在PBA系统中的决断集模板编译模块，我们采用把决断集模板编译成结构化查询语言来查找差异化实例替换$\theta$的方法。利用数据库的持久化存储特性，使我们的系统达到可扩展的要求，虽然计算速度相比在内存中搜索的方法要慢，但是这种方法降低了数据集大小的要求，使我们可以完成使用所有收集到的数据进行测试。最后一个模块是解释生成模块，解释生成模块实现了上文中列出的解释生成算法，根据决断集模板，观察值和训练集生成合理解释集。
\begin{figure}[htb]
  \center
  \includegraphics[width=0.55\textwidth]{img/7.jpg}\\
  \caption{PBA系统模块}\label{fig:fulladder}
\end{figure}


\section{解释基数对生成解释的效率以及数量对比实验}
	解释的生成是本文中的重要工作，因此生成的解释基数与生成解释的数量以及生成解释所需要的时间是评价解释生成工作的重要参考指标。
\subsection{实验设计}
	本次实验使用的数据集依旧是来自FreeBase的FB15K。解释基数对生成解释的效率以及数量对比实验对决断集模板的生成并不需要保证决断集模板的语义，因此我们根据训练集的实体字典集合训练集的二元关系字典集随机生成了5,000个观察值，根据生成的观察值我们利用脚本配合本体推理机Pellet生成了10,000个决断集模板。在实验的时候，我们按照解释基数的限制设置了十组实验，每组实验分别对应基数为1~10的解释。对于每组实验，我们记录PBA生成的解释的数量以及生成的解释所需要的时间，最后根据实验结果得出我们的结论。
\subsection{实验结果与数据分析}
	左图的数据是我们进行解释基数对生成解释的效率以及数量对比实验的实验结果，从图中可以看到，随着基数大小限制的增加，基于决断集模板生成的解释的个数也有所增加，但是基于决断集模板生成的解释个数的增长速率却相对平缓，得到了有效的控制，其中的原因包括：1)解释变量的允许。由于解释的生成是从决断集模板实例化而来，由$\mathcal{O} \cup \alpha$生成的差异化实例替换$\theta$不能保证结解释中所有的个体实例被覆盖，因此解释变量的允许是必须的也是有效的手段在保证语义的同时又限制解释的数量。2)由于我们的解释需要满足$\subseteq_\mathsf{ds}$-$\emph{minimal}$的限制，因此最终生成的解释的集合中可被替换生成的解释都被去掉，达到了减小解释数量的目的的同时又保证了所有的解释能够被表达。
	
	在右图我们可以看到在解释基数的变化下，生成每个解释的平均时间的变化情况。可以看到，随着解释基数的增加，生成每个合理解释的平均时间也开始逐渐增加。从图中的数据可以看到，基于决断集模版的解释在基数为1的情况下，对于所有的决断集模板和观察值，解释都可以在较短的时间内完成计算。一个原因是随着基数的增加，每次生成解释的时候需要进行检测一致性的解释数量有所增加，而检测$\subseteq_\mathsf{ds}$-$\emph{minimal}$特性的耗时也会相应增加，因此生成的解释平均时间就随着解释基数的上升而上升。
	
\section{决断集模板解释修复知识库模型对比实验}
	本实验主要考虑的问题是基于决断集模板诊断求解得出的解释是否能够对知识库模型有一个较好的修复作用。知识库的训练集具有强的语义表达能力，如果对于一个观察值知识库模型无法正确地对它进行表达，我们尝试利用决断集模版对它进行修复，修复的方式就是利用求解得到的基于决断集模版的解释对训练进行补充，对比诊断前后知识库模型对观察值的表达能力，我们可以验证解释集对知识库模型的修复能力。同时，由于基数的不同会对解释的修复能力产生影响，所以我们也对不同基数的解释的修复能力进行了比较。
\subsection{实验设计}
	我们对诊断结果的评价方法由[3]中的方法调整而来。在利用现有的构造知识库模型的方法构造出向量模型之后，我们使用观察值集作为测试集来对模型进行测试。测试的时候我们对于测试集中的三元组(称为“有效三元组”)进行拆散操作，例如对于三元组$(h,r,t)$，我们首先移除三元组中的实体$h$，然后使用实体集合中的实体构造新的三元组，这些三元组我们称为“损坏三元组”，然后我们在把有效三元组和损坏三元组放在一起进行计算，分别计算这些三元组的能量函数，最后根据能量得分对它们进行由高到低排列。我们关注的指标有两个，一个是$MeanRank$，表示测试集中有效三元组的平均排名，平均排名越高代表模型表达该三元组的能力越强。另一个指标是$hits@10$，它表示测试集中有效三元组进入排名前百分之10的比率，同$MeanRank$，$hits@10$的比率也是越高越好。 对比诊断前后的模型性能，我们就可以验证诊断结果对知识库模型的修复效果。
	
	我们按照基数对实验中计算出的解释进行划分，直观上地，在其它条件不变的情况下，基数越低的解释意味着训练集的数据中与决断集模板的重合度越高，所以可以非常合理的推测基数越低的解释在语义上觉有更高的可信度 。解释的生成条件虽然已经在定义中进行了限制，但是解释的数量仍然较大，因此我们对基数较低的解释赋予了更高的计算优先级，这样我们可以优先计算出语义可信度较高的解释。
	我们从有效三元组中抽取了500个作为观察值，根据观察值我们又利用脚本对FB15K的数据进行处理，根据实体关系的限制筛选出二元关系链的断言集合，然后我们请了语义网领域内的专家对数据进行复查，人工确认了其中正确的决断集。我们对处理后的数据进行转化，得到了决断集模版。我们用收集到的训练集、决断集模版以及观察值作为PBA系统的输入进行了决断集模板解释修复知识库模型对比实验。
	
\subsection{实验结果与数据分析}
		
	\begin{table}[!h]
	\caption{实验环境}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
         \multirow{3}{*}{Cardinity} &\multicolumn{4}{c|}{TransE}&\multicolumn{4}{c|}{TransR}& \multicolumn{4}{c|}{TransH} \\
		 \cline{2-13}
                & \multicolumn{2}{c|}{$MeanRank$} & \multicolumn{2}{c|}{$Hit@10$}& \multicolumn{2}{c|}{$MeanRank$}& \multicolumn{2}{c|}{$Hit@10$}& \multicolumn{2}{c|}{$MeanRank$}& \multicolumn{2}{c|}{$Hit@10$}\\
		 \cline{2-13}
                & Raw & Filter & Raw& Filter& Raw& Filter& Raw& Filter& Raw& Filter& Raw& Filter\\
		\hline
           $No\ $ Exp   & 59.172 & 47.0 & 43.3&63.1 & 51.45& 38.3& 48.36& 65.0& 49.18& 42.47& 49.72& 62.02\\
		\hline
           Exp.$ C = 1$     & 21.37 & 16.39 & 54.78& 82.8& 22.13& 15.98& 63.7& 88.4& 32.03& 24.77& 60.13& 86.02\\
		\hline
           Exp.$ C = 2$     & 26.13 & 20.56 & 48.24& 78.75 & 27.76& 20.81& 60.07& 84.14& 34.01& 23.68& 57.04& 85.06\\
		\hline
           Exp.$ C = 3$     & 49.0 & 40.76 & 45.33 & 68.46 & 25.0& 19.88& 57.12& 81.35& 38.88& 31.3& 55.0& 80.42\\
		\hline
           Exp.$ C = 4$     & 54.34& 38.12 & 45.77& 62.45& 33.63& 24.42& 51.34& 76.79& 44.43& 32.45& 56.02& 79.44\\
		\hline
\end{tabular}
\end{center}
\vspace*{-5mm}
\end{table}
	
	在本次实验中我们用来验证诊断效果的知识库模型包括以下：TransE(Bordes et al., 2013)，TransH (Wang et al., 2014)以及TransR (Lin et al.,
	2015)\cite{Lin15}。模型的实现代码来自\url{https://github.com/mrlyk423/relation_extraction}，由Lin等人实现。在表4.3中记录了我们的实验数据，在表的左边列出了我们使用的知识库模型。在表的左侧$No\ $Exp，Exp.$ C = 1$，Exp.$ C = 2$，Exp.$ C = 3$，Exp.$ C = 4$以及Exp.$ C = 5$，表示我们根据生成的解释基数进行分类。根据解释的基数的不同我们共进行了六轮实验，其中实验$No\ $Exp表示的是基准测试，在这个测试中我们使用三种知识库模型对生成的观察值集合进行链接预测任务。
	
		在实验结果的第二行列出了上文提到的两种评价方法$MeanRank$，$hits@10$。对于每一种评价方法，我们使用Lin等人的方法生成了两组测试数据分别是Raw测试组和Filter测试组\cite{ptranse}。Raw测试组的生成方式与Bordes等人及之前的生成方式一致，使用知识库个体字典中的随机个体替换测试三元组的头实体和尾实体。这种方式的不合理地方在于随机替换的个体有可能会生成训练集中的正向测例，这类测例通常会获得较高的正向得分，从而导致测试集中的数据排名下降。因此在Raw测试数据的基础上加上了过滤操作，剔除了所有训练集中包含的数据。另外值得注意的是，测试三元组的生成有替换头实体和替换尾实体两种方式，但是我们在生成解释时并没有对解释的头尾实体进行区分，因此最后的实验结果是对两种方式生成的测试三元组进行统一计算得出的。
		
		从整体上看，诊断的结果除在极个别情况下，都使得训练出的模型产生了正向的效果，利用解释集重新训练出的模型，在对测试集的链接预测任务上取得了不同幅度上的提升，包括参与测试三个知识库模型TransE，TransH和TransR。纵向地看，在所有情况下，基数为1的解释集都取得了最好的结果，这也符合人们在语义上的推理习惯。一般情况下，基数为1的时侯决断集模版与原知识库有着较高的匹配度，这也使得提出的假设有着更多的客观事实作为支撑。当基数继续的时候，解释集对知识库的修复能力开始下降，特备的，在经受测试的三种模型中，在解释集基数达到3和4时，重新构建的模型已经无法做到很好地对知识库模型进行修复。其中一个原因是当解释集基数增大时，知识库与决断集的重合度降低，从而降低了解释假设的合理性。横向的看，基数为2的时候，解释集对TransE模型的修复效果下降较快，但是对TransH和TransR仍然有着较好的修复效果，我们相信这与TransE无法很好地处理一对多、多对多关系的原因有关。
		
