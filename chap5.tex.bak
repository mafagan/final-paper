\chapter{实验与分析}
在上两章的理论中，我们提出了基于决断集模板进行溯因诊断的方法，因此在本章中我们进行了两组实验来对上述理论进行验证。在第一组实验中，我们主要观察基于决断集模板的解释的基数生成解释的数量的影响以及生成决断集模板算法的计算效率。在第二组实验中我们观察生成的解释对知识库模型的诊断修复效果。

\section{实验工具与环境}
在本文中，我们实现了算法2和3中的算法逻辑，并把程序命名成Pattern Based Abduction(PBA)。PBA是一个用Java写成的程序，其中我们使用了本体语言编辑库OWL API来进行本体的生成、编辑与持久化存储，本体语言的推理机我们使用的是 Pellet API\cite{SPGKK07}，我们利用Pellet API完成的主要任务包括蕴含检测，蕴含寻找以及一致性检测。我们使用的数据库系统是Mysql，利用Mysql我们主要完成以下几个任务：第一是完成数据的存储。这里的数据主要包括本体中的ABox，训练集的数据和测试数据，实验完成后生成的解释集合也会存储在相同数据库的不同表中。使用Mysql完成的第二个主要任务是寻找差异化实例替换$\theta$。通过把决断集模板编译成sql语句后，我们可以根据数据库中的存储的公理计算出相对应的差异化实例替换$\theta$。本文实验中用到的实验数据如下表：

\begin{table}[!h]
	\caption{实验工具}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
{\rule{\temptablewidth}{1pt}}\\
\begin{tabular}{c|c}
    工具 & 描述  \\
    \hline
    开发语言 & Java \\
    \hline
    JDK & 7u121-2.6.8-1ubuntu0.14.04.3  \\
    \hline
    数据库 & Mysql(vesion 5.7)\\
    \hline
    本体编辑库 & OWL API(vesion 3.5.1)\\
	\hline
    本体推理机 & Pellet API(version 2.3.1)\\
	\hline
\end{tabular}\\
{\rule{\temptablewidth}{1pt}}
\end{center}
\vspace*{-5mm}
\end{table}



本次实验的数据，我们使用的两组知识库数据都来自FreeBase，分别是FB15K和FB40K。因为$\Delta_p$的问题输入需要设置观察值，因此我们对这组数据进行了预处理，观察值的设置会在训练集中被选取，同时也会从训练集中把这组数据移除，以避免影响实验结果。 它们的具体数据如下表：
\begin{table}[!h]
\caption{FreeBase数据集相关数据}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
\begin{tabular}{c|ccccc}
	\hline
    Dataset & \#Rel & \#Ent & \#Train & \#Valid & \#Observation  \\
    \hline
    FB15K & 1,345 & 14,951 & 483,142 & 50,000 & 59,071 \\
    \hline
    FB40K & 1,336 & 39,528 & 370,648 & 67,946 & 96,678 \\
	\hline
\end{tabular}\\
\end{center}
\vspace*{-5mm}
\end{table}



我们的实验运行在以下机器上，机器的配置如下：
	\begin{table}[!h]
	\caption{实验环境}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
{\rule{\temptablewidth}{1pt}}\\
\begin{tabular}{c|c}
    环境 & 描述  \\
    \hline
    CPU &  Dual-Core 2.60GHz \\
    \hline
    RAM & 8GB  \\
    \hline
    OS & Windows 7\\
    \hline
    Java Heap Space & 8GB
\end{tabular}\\
{\rule{\temptablewidth}{1pt}}
\end{center}
\vspace*{-5mm}
\end{table}

\section{程序框架}
系统PBA采取了分模块设计，所有的模块如图4.1所示，其中数据解析模块负责对输入的数据集进行解析，并结合本体编辑推理模块完成对数据集的语义表达。本体编辑推理模块除了完成对数据集语义表达的任务以外，还需要完成本体编辑存储以及推理任务，其中推理模块需要在解释生成的过程中对生成的本体和解释进行一致性检测，并验证临时本体是否能够蕴含蕴含值(或观察值)。决断集模板编译模块主要完成寻找差异化实例替换$\theta$的任务。寻找
差异化实例替换$\theta$的任务可以在内存中通过搜索的方式找到，并且计算速度较快，但是因为计算机资源有限，而数据的增大有可能导致计算任务的无法完成，所以我们会把在内存中完成差异化实例替换$\theta$的这种方式称为不可扩展的。在PBA系统中的决断集模板编译模块，我们采用把决断集模板编译成结构化查询语言来查找差异化实例替换$\theta$的方法。利用数据库的持久化存储特性，使我们的系统达到可扩展的要求，虽然计算速度相比在内存中搜索的方法要慢，但是这种方法降低了数据集大小的要求，使我们可以完成使用所有收集到的数据进行测试。最后一个模块是解释生成模块，解释生成模块实现了上文中列出的解释生成算法，根据决断集模板，观察值和训练集生成合理解释集。
\begin{figure}[htb]
  \center
  \includegraphics[width=0.55\textwidth]{img/7.jpg}\\
  \caption{PBA系统模块}\label{fig:fulladder}
\end{figure}


\section{解释基数对生成解释的效率以及数量对比实验}
	解释的生成是本文中的重要工作，因此生成的解释基数与生成解释的数量以及生成解释所需要的时间是评价解释生成工作的重要参考指标。
\subsection{实验设计}
	
	本次实验我们收集了10个本体，这些本体的部分数据已经在表5.4中罗列出来。注意其中\#C 是概念名的数量，\#R 是二元关系的数量，\#A 是本体中公理的个数，\#E 本体推理出的原子公理的个数，DL的表达能力由Pellet检测。第一个本体是著名的LUBM(Guo, Pan, and Heflin 2005)本体。之后两个是UOBM(Ma et al. 2006) 本体。他们扩展了LUBM，在LUBM的基础上他们添加了OWL Lite特性以及OWL DL的特性。之后四个本体是从\url{ http://protegewiki.stanford.edu/
wiki/Protege_Ontology_Library}。这四个本体主要描述家庭关系，哲学领域，酒以及早期的GALEN模型的原型。最后的三个本体是大型的本体，它们主要描述医疗相关领域的知识，我们是从\url{ http://www.opengalen.org/
download/opengalen8-owl-sources.zip}收集的。
	
	
	为了展示我们计算基于决断集模版解释的方法的实用性，我们进行以下实验。我们在实验中根据生成的观察值以及决断集模版，分别计算基数为1和基数为2的解释。每一个生成的蕴含公理我们验证了它无法被测试本体蕴含，并且不会产生不一致。我们生成的决断集模版都是从本体中具有最高$support$值的，因此基于决断集模版生成的解释有更大的可能性被成功实例化。对于每一个基数设置为$k$(其中$k \in \{1,2\}$)的实验，我们对实验设置了10000秒的限制，即使时间到了我们也可以观察到已完成计算的任务数据。
	\begin{table}[!tb]
\caption{测试本体数据}\label{tab:complexity}
\begin{small}
\centering
\begin{tabular}{|@{\,}c@{\,}|@{\,}c@{\,}|r|r|r|r|}
 \hline
TBox & DL Expressivity & \#C & \#R & \#A & \#E \\
 \hline
LUBM & $\mathcal{ALEHI}_+(\mathbf{D})$ & 43 & 32 & 93 & 76 \\
UOBM-Lite & $\mathcal{ALEHIN}_+(\mathbf{D})$ & 52 & 43 & 145 & 86 \\
UOBM-DL & $\mathcal{SHOIN}(\mathbf{D})$ & 69 & 44 & 206 & 113 \\
generations & $\mathcal{ALCOIF}$ & 18 & 4 & 38 & 45 \\
wine & $\mathcal{SHOIN}(\mathbf{D})$ & 77 & 14 & 657 & 322 \\
philosurfical & $\mathcal{AL}$ & 377 & 313 & 1465 & 2981 \\
not-galen & $\mathcal{ALEHF}_+$ & 3097 & 413 & 5771 & 32475 \\
physiology & $\mathcal{ALEI}$ & 2129 & 134 & 2256 & 2146 \\
drugs & $\mathcal{ALEHIF}(\mathbf{D})$ & 4258 & 89 & 5042 & 17103 \\
pathology & $\mathcal{ALEI}(\mathbf{D})$ & 7378 & 258 & 7159 & 14235 \\
 \hline
\end{tabular}
\\[4pt]
\end{small}
\end{table}



\subsection{实验结果与数据分析}
	

	\begin{table}[!h]
	\caption{在本体中生成解释的相关数据}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & \multicolumn{2}{c|}{JP-Comp} &
 \multicolumn{3}{c|}{JPBE1-Comp} &
 \multicolumn{3}{c|}{JPBE2-Comp} \\
 \cline{2-9}
 TBox & \#P & T(s) & \#TP & T1(s) & \#E & \#TP & T2(s) & \#E \\
 \hline
LUBM & 17 & *1.0 & 17 & 3.9 & 253 & 17 & 178.8 & 18898 \\
UOBM-Lite & 23 & *1.3 & 23 & 5.5 & 342 & 23 & 250.5 & 39870 \\
UOBM-DL & 44 & *2.3 & 44 & 6.1 & 255 & 44 & 290.7 & 40659 \\
generations & 31 & *0.9 & 31 & 2.7 & 182 & -- & -- & -- \\
wine & 894 & *86.6 & 100 & 66.7 & 0 & 100 & 188.9 & 10948 \\
philosurfical & 12 & *7.6 & 12 & 89.7 & 1834 & 7 & 7111.4 & 724961 \\
not-galen & 1000 & 1340.9 & 100 & 72.0 & 1384 & 3 & 5637.8 & 144626 \\
physiology & 274 & *14.8 & 100 & 108.7 & 477 & 98 & 9996.8 & 398521 \\
drugs & 289 & *69.6 & 100 & 193.3 & 617 & 4 & 2749.2 & 49650 \\
pathology & 1000 & 122.8 & 100 & 112.6 & 935 & 7 & 4161.8 & 29759 \\
 \hline
\end{tabular}\\
\end{center}
\vspace*{-5mm}
\end{table}	
	
	
	在表5.5中，JP-Comp展示了对于每个测试本体计算最多1000个决断集模版的时间，如果计算出的决断集模版少于1000，那么表中的数据就是实际计算出的数据。表中报告的数据包括加载本体的时间。
	
	需要注意的是在表中: \#P 计算出的决断集模版; T 是计算最多1000个决断集模版所需要的时间 (*表示所有的决断集都被计算出来); \#TP 是在10000内得到的所有$support$值最高的决断集模版; T1 (T2) 是使用这些决断集模版生成解释过程中消耗的时间; \#E 是在完全处理完决断集模版后对于生成的50个观察值的解释的总数。
	
	在“JPBE$k$-Comp”部分展示的是对于每一个测试本体，基于$support$值最高的100个决断集模版对生成的50个观察值计算所有的基数为$k$的解释的运行数据。当$k$等于1的时候，在所有的10个测试本体中，100个高频决断集模版都被处理完成。
	
	但是$k=1$的设定无法保证至少一个解释被生成，所以我们又做了第二轮试验，计算所有基数为2的解释。当$k$被设置为2的时候，在$generations$的本体中我们无法生成解释。因为在$generations$中所有的解释基数都为1。对于其它的本体，当$k=2$且限时10000秒内，它们中至少有一部分的决断集模版已经被处理完，也就意味着相应的解释全部计算完成。这个实验展示了我们基于决断集模版生成解释的方法具有实用性。同时实验结果也表明对计算出来的解释集应该需要进一步的处理。
	
	
\begin{figure}[htb]
  \center
  \includegraphics[width=0.85\textwidth]{img/14.jpg}\\
  \caption{对于一个观察值计算解释的平均耗时}\label{fig:fulladder}
\end{figure}
	
\section{决断集模板解释修复知识库对比实验}
	本实验主要考虑的问题是基于决断集模板诊断求解得出的解释是否能够对知识库模型有一个较好的修复作用。知识库的训练集具有强的语义表达能力，如果对于一个观察值知识库模型无法正确地对它进行表达，我们尝试利用决断集模版对它进行修复，修复的方式就是利用求解得到的基于决断集模版的解释对训练进行补充，对比诊断前后知识库模型对观察值的表达能力，我们可以验证解释集对知识库模型的修复能力。同时，由于基数的不同会对解释的修复能力产生影响，所以我们也对不同基数的解释的修复能力进行了比较。
\subsection{实验设计}
	我们对诊断结果的评价方法由\cite{ptranse}中的方法调整而来。在利用现有的构造知识库模型的方法构造出向量模型之后，我们使用观察值集作为测试集来对模型进行测试。测试的时候我们对于测试集中的三元组(称为“有效三元组”)进行拆散操作，例如对于三元组$(h,r,t)$，我们首先移除三元组中的实体$h$，然后使用实体集合中的实体构造新的三元组，这些三元组我们称为“损坏三元组”，然后我们再把有效三元组和损坏三元组放在一起进行计算，分别计算这些三元组的能量函数，最后根据能量得分对它们进行由高到低排列。我们关注的指标有两个，一个是$MeanRank$，表示测试集中有效三元组的平均排名，平均排名越高代表模型表达该三元组的能力越强。另一个指标是$hits@10$，它表示测试集中有效三元组进入排名前百分之10的比率，同$MeanRank$，$hits@10$的比率也是越高越好。 对比诊断前后的模型性能，我们就可以验证诊断结果对知识库模型的修复效果。
	
	我们按照基数对实验中计算出的解释进行划分，直观上地，在其它条件不变的情况下，基数越低的解释意味着训练集的数据中与决断集模板的重合度越高，所以可以非常合理的推测基数越低的解释在语义上觉有更高的可信度 。解释的生成条件虽然已经在定义中进行了限制，但是解释的数量仍然较大，因此我们对基数较低的解释赋予了更高的计算优先级，这样我们可以优先计算出语义可信度较高的解释。
	我们的观察值从有效三元组中抽取，再根据观察值我们对训练数据进行了预处理，以使得训练集中不包含测试集中的数据。我们还使用了Peng等人提供的训练集本体，并利用决断集生成算法计算出的决断集。我们对处理后的数据进行转化，得到了决断集模版。最后我们使用训练集、决断集模版以及观察值作为PBA 系统的输入进行了决断集模板解释修复知识库模型对比实验。
	
\subsection{实验结果与数据分析}
		
	\begin{table}[!h]
	\caption{诊断实验数据}\label{tab_environment}
\vspace*{-5mm}
\tabcolsep 2pt
\wuhao
\begin{center}
\def\temptablewidth{0.495\columnwidth}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
         \multirow{3}{*}{Cardinity} &\multicolumn{4}{c|}{TransE}&\multicolumn{4}{c|}{TransR}& \multicolumn{4}{c|}{TransH} \\
		 \cline{2-13}
                & \multicolumn{2}{c|}{$MeanRank$} & \multicolumn{2}{c|}{$Hit@10$}& \multicolumn{2}{c|}{$MeanRank$}& \multicolumn{2}{c|}{$Hit@10$}& \multicolumn{2}{c|}{$MeanRank$}& \multicolumn{2}{c|}{$Hit@10$}\\
		 \cline{2-13}
                & Raw & Filter & Raw& Filter& Raw& Filter& Raw& Filter& Raw& Filter& Raw& Filter\\
		\hline
           $No\ $ Exp   & 50.172 & 41.0 & 43.3&63.1 & 39.45& 26.3& 52.36& 72.0& 42.18& 30.47& 54.72& 76.02\\
		\hline
           Exp.$ C = 1$     & 27.37 & 16.39 & 54.78& 82.8& 22.13& 15.98& 63.7& 81.4& 32.03& 24.77& 58.13& 86.02\\
		\hline
           Exp.$ C = 2$     & 29.13 & 20.56 & 48.24& 78.75 & 27.76& 17.81& 60.07& 84.14& 39.01& 23.68& 57.04& 85.06\\
		\hline
           Exp.$ C = 3$     & 46.0 & 40.76 & 41.33 & 68.46 & 25.0& 19.88& 57.12& 81.35& 38.88& 31.3& 55.0& 80.42\\
		\hline
           Exp.$ C = 4$     & 47.34& 38.12 & 45.77& 62.45& 33.63& 24.42& 51.34& 76.79& 44.43& 32.45& 56.02& 79.44\\
		\hline
\end{tabular}
\end{center}
\vspace*{-5mm}
\end{table}
	
	在本次实验中我们用来验证诊断效果的知识库模型包括以下：TransE，TransH以及TransR\cite{Lin15}，其中程序参数有以下设置：$\lambda=0.001,\gamma=1,dim=100$。模型的实现代码来自\url{https://github.com/mrlyk423/relation_extraction}，由Lin等人实现。在表5.6中记录了我们的实验数据，在表的左边列出了我们使用的知识库模型。在表的左侧$No\ $Exp，Exp.$ C = 1$，Exp.$ C = 2$，Exp.$ C = 3$以及Exp.$ C = 4$表示我们根据生成的解释基数对数据进行分类。根据解释的基数的不同我们共进行了五轮实验，其中实验$No\ $Exp 表示的是基准测试，在这个测试中我们使用三种知识库模型对生成的观察值集合进行链接预测任务。
	
		在实验结果的第二行列出了上文提到的两种评价方法$MeanRank$，$hits@10$。对于每一种评价方法，我们使用Lin等人的方法生成了两组测试数据分别是Raw测试组和Filter测试组\cite{ptranse}。Raw测试组的生成方式与Bordes等人及之前的生成方式一致，使用知识库个体字典中的随机个体替换测试三元组的头实体和尾实体。这种方式的不合理地方在于随机替换的个体有可能会生成训练集中的正向测例，这类测例通常会获得较高的正向得分，从而导致测试集中的数据排名下降。因此在Raw测试数据的基础上加上了过滤操作，剔除了所有训练集中包含的数据。另外值得注意的是，测试三元组的生成有替换头实体和替换尾实体两种方式，但是我们在生成解释时并没有对解释的头尾实体进行区分，因此最后的实验结果是对两种方式生成的测试三元组进行统一计算得出的。
		
		从整体上看，诊断的结果除在极个别情况下，都使得训练出的模型产生了正向的效果，利用解释集重新训练出的模型，在对测试集的链接预测任务上取得了不同幅度上的提升，包括参与测试三个知识库模型TransE，TransH和TransR。总体来看，基数为1的解释集都取得了最好的结果，这也符合人们在语义上的推理习惯。一般情况下，基数为1的时侯决断集模版与原知识库有着较高的匹配度，这也使得提出的假设有着更多的客观事实作为支撑。当基数继续的时候，解释集对知识库的修复能力开始下降，特别的，在经受测试的三种模型中，在解释集基数达到3和4时，重新构建的模型已经无法做到很好地对知识库模型进行修复。其中一个原因是当解释集基数增大时，知识库与决断集的重合度降低，从而降低了解释假设的合理性。横向的看，基数为2的时候，解释集对TransE模型的修复效果下降较快，但是对TransH和TransR仍然有着较好的修复效果，我们相信这与TransE无法很好地处理一对多、多对多关系的原因有关。
		
